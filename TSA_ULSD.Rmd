---
title: "TSA - ULSD"
author: "Nathaniel McNalley, Fashuai Li, Hongtian Fu, and Taylor Armbruster"
date: "`r Sys.Date()`"
output: html_document
resource_files:
- TSA_template.Rmd
- TSA_template.Rmd
---

<style type="text/css"> body, td {font-size: 12px;} code.r{font-size: 10px;} pre {font-size: 10px} </style>

```{r, echo = F, warning=FALSE, message = FALSE}
knitr::opts_chunk$set(echo = F,warning = F,message = F, fig.width = 4, fig.height = 3,fig.align = "center",tidy = FALSE, strip.white = TRUE)
library(RTL)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(purrr)
library(scales)
#Morningstar API Login
iuser <-  "morningstar.ctrd@ualberta.ca"
ipassword <-  "oRakvwtPVg"
EIAkey <-  "7658ca55759776ff3116f4e3e927948e"
```

**this template is a guide to organize your project in a clear manner**

**quality of presentation refers amongst others to showing code, tables and charts in a manner that flows with your story. Details and computations shall remain in the code chunks without being rendered into the html output.**

## Experimentation Part

```{r}
#Extracting the March and April Contracts
df <- RTL::getPrices(
  feed = "CME_NymexFutures_EOD",
  contracts = c("@HO22H","@HO22J","@CL22H","@CL22J"),
  from = "2019-08-01",
  iuser = iuser,
  ipassword = ipassword) 
#Extracting the 1st and 2nd Contracts
df2 <- RTL::getPrices(
    feed = "CME_NymexFutures_EOD_continuous",
    contracts = c("HO_001_Month","HO_002_Month","CL_001_Month","CL_002_Month"),
    from = "2019-08-01",
    iuser = iuser,
    ipassword = ipassword)
#Joining the Data Frames, converting to barrels, and calculating spreads
HOdf <- dplyr::inner_join(df,df2) %>% 
    dplyr::arrange(dplyr::desc(date)) %>% 
  stats::na.omit()%>% 
  dplyr::transmute(date = date,
                   HO_01 = HO_001_Month * 42,
                   HO_02 = HO_002_Month * 42,
                   CL_01 = CL_001_Month,
                   CL_02 = CL_002_Month,
                   HO22H = HO22H * 42,
                   HO22J = HO22J * 42,
                   CL22H = CL22H,
                   CL22J = CL22J,
                   HO_c1c2_Spd = HO_01 - HO_02,
                   HO_Apr22_Mar22_Spd = HO22H - HO22J,
                   HO_Crack_Spd = HO22H - CL22H) %>% 
#Converting from wide to long
  tidyr::pivot_longer(-date, values_to = "Price", names_to = "Contracts")
```

```{r  echo=FALSE, message=FALSE, fig.align="center"}
#Plotting flat price for 1st and 2nd contracts
HOdf %>% 
  dplyr::filter(stringr::str_detect(Contracts, "_0")) %>% 
  plotly::plot_ly(
    width = 700, height = 400,
    x = ~date,
    y = ~Price,
    name = ~ Contracts,
    type = 'scatter',
    mode = 'lines'
  ) %>% 
  plotly::layout(
    title = "Flat Price USLD vs. WTI", x = 0,
  xaxis = list(title = "Date"),
  yaxis = list(
    title = "$ per Barrel")
  )
```

```{r}
#Plotting flat price for March and April contracts 
HOdf %>% 
  dplyr::filter(stringr::str_detect(Contracts,c("CL22H", "CL22J", "HO22H", "HO22J")))%>% 
  plotly::plot_ly(
    width = 700, height = 400,
    x = ~date,
    y = ~Price,
    name = ~ Contracts,
    type = 'scatter',
    mode = 'lines'
  ) %>% 
  plotly::layout(
    title = "Flat Price March & April", x = 0,
  xaxis = list(title = "Date"),
  yaxis = list(
    title = "$ per Barrel")
  )
```


```{r}
#Time spread 1st and 2nd contracts for ULSD
HOdf %>% 
  dplyr::filter(stringr::str_detect(Contracts, "c1c2")) %>% 
  plotly::plot_ly(
    width = 700, height = 400,
    x = ~date,
    y = ~Price,
    name = ~Contracts
  ) %>% 
  plotly::add_lines() %>% 
  plotly::layout(
    title = "Time Spread: HO_01 vs HO_02", x = 0,
  xaxis = list(title = "Date"),
  yaxis = list(
    title = "$ per Barrel")
  )
```

```{r}
#Time spread for March and April ULSD contracts 
HOdf %>% 
  dplyr::filter(stringr::str_detect(Contracts, "Apr")) %>% 
  plotly::plot_ly(
    width = 700, height = 400,
    x = ~date,
    y = ~Price,
    name = ~Contracts
  ) %>% 
  plotly::add_lines() %>% 
  plotly::layout(
    title = "Time Spread: March and April 2022", x = 0,
  xaxis = list(title = "Date"),
  yaxis = list(
    title = "$ per Barrel")
  )
```

```{r}
#Crack spread between ULSD and WTI
HOdf %>% 
  dplyr::filter(stringr::str_detect(Contracts, "Crack")) %>% 
  plotly::plot_ly(
    width = 700, height = 400,
    x = ~date,
    y = ~Price,
    name = ~Contracts
  ) %>% 
  plotly::add_lines() %>% 
  plotly::layout(
    title = "ULSD Crack Spread: WTI March 2022", x = 0,
  xaxis = list(title = "Date"),
  yaxis = list(
    title = "$ per Barrel")
  )
```
```{r}
#ULSD is also used for heating oil in some homes in the US and Canada so we would expect to see some seasonality in demand and pricing. US residential use is most common in the northeastern states of New York and Pennsylvania and into New England. These locations account for 86% of total US residential heating oil use. To attempt to visualize any relationship between USLD prices and the temperatures of colder winter months we decided to pull temperature data for New York. 
#Still work in progress
```

```{r, eval=FALSE}
#Weather Data - Relevant to ULSD
#riem is the data package for weather data services
#Still work in progress
library(riem)

nyc_weather <- riem::riem_measures(station = "NYC",
                    date_start = "2010-01-01",
                    date_end = Sys.Date()) %>% 
  tidyr::separate(valid, c("date", "time"), sep = " ") %>% 
  base::subset(select = c(date,tmpf)) %>% 
  dplyr::group_by(date) %>% 
  dplyr::mutate(temp = mean(tmpf)) %>% 
  ungroup(date) %>% dplyr::select(-tmpf) %>% distinct() %>% 
  stats::na.omit() %>% dplyr::mutate(date = as.Date(date))
#Graphical Depication
p <- nyc_weather %>% 
  ggplot(aes(y = temp, x = date, col = temp, alpha = 1, show.legend = FALSE)) +
  geom_point() + 
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  labs(
    title = "NYC Temperature",
    caption = "Source: IEM",
    y = "Temperature (F)",
    x = "")
ggplotly(p)
```
## Summary
The main futures contracts used to trade ULSD will be the NY Harbor ULSD Futures (ticker HO). These contracts are standardized to 42,000 gallons (1,000 barrels). The ULSD delivery location is New York Harbor with options for delivery into the buyer's barge, tanker, or pipeline if they are able. The product must meet the specification of the Colonial Pipeline's Fungible Grade 62 for Ultra Low Sulfur Diesel and must be designated for sale in accordance with U.S. Environmental Protection Agency regulations. As of 2016, almost all petroleum-based diesel fuel available in the UK, mainland Europe, and North America is ultra low sulphur. 

NY Harbor ULSD Futures Handbook: https://www.cmegroup.com/content/dam/cmegroup/rulebook/NYMEX/1a/150.pdf  

ULSD is also commonly referred to as distillate and is the second-most consumed petroleum product in the United States. In addition to its use as a transportation fuel, distillate is also consumed for heating and power generation purposes. Distillate's use as a heating fuel drives the seasonal pattern of higher consumption during the winter months. Distillate consumption is affected by economic growth and weather conditions as well as vehicle efficiency and miles traveled of heavy-duty vehicles.

### What's changed

### Current Exposure

### New Trades if any

## Form a Market View

### Supply Demand Indicators

Production: Most of the diesel fuel produced and consumed in the US is refined from crude oil at petroleum refineries within the US. These refineries produce an average of 11 to 12 gallons of diesel fuel for every 42 gallon barrel of crude. Production decisions by refineries are also effected by the sprad between diesel and gasoline prices as when the spread widens refineries increase the amount of diesel that they produce relative to gasoline. The standard crack-spread at refineries is generally 3-2-1, meaning that for 3 barrels of crude that 2 will be refined into gasoline and 1 will be refined into ULSD.

Consumption: More than 8 million mones in New Englad and the Central Atlantic Region of the US lack access to natural gas so they use Heating Oil (ULSD). This makes one of ULSDâ€™s end markets consumers those who require ULSD for their home heating needs. Due to this there is some seasonality in pricing during the cold winter months. Residential heating oil consumption peaked in the 1970's and declined nearly every year since. 81%  of residential heating use is concentrated in the US Northeast including New York, Pennsylvania, and New England. Diesel is mainly used as a transport fuel and consumption is impacted by the underlying economic conditions, fuel efficiency, and miles traveled by heavy duty vehicles. In 2020, diesel fuel consumption was about 44.61 billion gallons which averages to about 122 million gallons per day. PADD 3 has been a net exported of diesel since 2001 which is logical given the number of refineries located in the US Gulf Coast and the fuel needs across the US. 

Components of the price you see at the pumps: The cost of crude oil purchased by refineries, refining costs, distribution and marketing costs, and state taxes all influence the price you see at the pumps.

Location Prices for Diesel: There are a few different geographic markets for diesel including Chicago ULSD, NYH ULSD, Gulf Coast ULSD, Los Angeles ULSD, Northwest Europe ULSD, and Singapore gasoil 500PPM.

Transportation: Most diesel fuel moves by pipeline from refineries and ports to terminals near major consuming areas. Barges and trains also move diesel to terminals. Trucks transport the diesel fuel from the terminals to retail service stations and to large volume consumers such as fleet operators. 
```{r}
# You are expected to build your own SD balance from the EIA and other website APIs
# It is by no means a substitute for doing your own research
library(RTL)
data("tickers_eia")
sd <- tickers_eia %>% dplyr::filter(sd_category == "dist", category != "stocks") %>% 
dplyr::as_tibble()

eia_df <- tibble::tribble(~ticker, ~name) %>% 
  add_row(ticker = sd$tick.eia[1:nrow(sd)], name = sd$tick.r[1:nrow(sd)]) %>% 
  dplyr::mutate(key = EIAkey) %>% 
  dplyr::mutate(df = purrr::pmap(list(ticker, key, name), .f = RTL::eia2tidy)) %>% 
  dplyr::select(df) %>% tidyr::unnest(df)
  
fig.title = "ULSD US SD Balance Components (kbd)"

p1 <- eia_df %>% 
  dplyr::filter(date >= "2000-01-01") %>% 
  ggplot(aes(x = date, y = value, color = series)) +
  geom_line() + 
  scale_y_continuous(labels = comma) +
  labs(title = fig.title, y = "kbd", x = "")
p1 %>% ggplotly(width = 700, height = 400,)
```

```{r}
#Implied storage builds and draws
data2 <- eia_df %>% 
  tidyr::pivot_wider(date, names_from = series, values_from = value) %>% 
  dplyr::rename(Demand = eia.mdist.demand, Imports = eia.mdist.imports, Supply = eia.mdist.supply, Exports = eia.mdist.exports) %>%   dplyr::arrange(date) %>% 
  dplyr::filter(date >= "2010-01-01") %>% 
  tidyr::drop_na() %>% 
  dplyr::mutate(Storage = Supply + Imports - Demand - Exports)

#Graphical Transformation
fig.title = "Implied Storage Builds/Draws for ULSD"
p <- data2 %>% 
  tidyr::pivot_longer(-date, names_to = "series", values_to = "value") %>% 
  ggplot(aes(x = date, y = value, color = series,width = 700, height = 400,)) + 
  geom_line() +
  scale_y_continuous(labels = scales::comma) +
  labs(title = fig.title, y = "kbd", x = "")
p %>% plotly::ggplotly(width = 700, height = 400,)
```


```{r}
#Transport Services Index
#TSI is indexed at 100 which was the average of the index for January 2000.
#Truck Tonnage Index is an indicator of shipping activity and consumption of goods. Gross tonnage of freight transport each month
#Freight TSI measures the volume of freight moved monthly in the US
#Passenger TSI measures changes in passenger travel 
#https://data.bts.gov/stories/s/9czv-tjte#demand-for-for-hire-transportation-services
library(RSocrata)
fig.title = "US Transport Indicies"
RSocrata_Key <- "34EB8ySLaX2e5P78xYb5TnmtP"
US_Transport_df <- read.socrata("https://data.bts.gov/resource/bw6n-ddqk.json", app_token = RSocrata_Key)
US_Transport_df <- US_Transport_df %>% dplyr::select(obs_date, truck_d11, tsi_freight, tsi_passenger) %>% 
  dplyr::rename(Date = obs_date, Truck_Tonnage_Index = truck_d11, Freight_TSI = tsi_freight, Passenger_TSI = tsi_passenger) %>% 
  tidyr::pivot_longer(-Date, names_to = "series", values_to = "values") %>% 
  dplyr::mutate(Date = as.Date(Date)) %>% 
  stats::na.omit()
US_Transport_df[ ,3] <- sapply(US_Transport_df[ , 3], as.numeric)
Transport_Indicies <- US_Transport_df %>% 
  ggplot(aes(x = Date, y = values, color = series,width = 700, height = 400,)) + 
  geom_line() +
  scale_y_continuous(labels = scales::comma)+
  labs(title = fig.title, y = "Index Value", x = "Date")
Transport_Indicies %>% plotly::ggplotly(width = 700, height = 400,)
```


```{r}
#download and save weather data into local:

# library(riem)
# station_id_vec = c("NYC","PHL","BOS","BDR","PWM")
# 
# 
# weather <-
#   riem::riem_measures(station = station_id_list[[2]],
#                       date_start = "2010-01-01",
#                       date_end = Sys.Date()) %>%
#   tidyr::separate(valid, c("date", "time"), sep = " ") %>%
#   base::subset(select = c(date, tmpf)) %>%
#   dplyr::group_by(date) %>%
#   dplyr::mutate(temp = mean(tmpf)) %>%
#   ungroup(date) %>% dplyr::select(-tmpf) %>% distinct() %>%
#   stats::na.omit() %>% dplyr::mutate(date = as.Date(date))
# 
# 
# weather  
# write.table(weather,"PWM.csv",sep = ",")


```
```{r }
#load data from csv files

library(dplyr)
df_NYC = read.csv("NYC.csv",sep = ",")
df_PHL = read.csv("PHL.csv",sep = ",")
df_BOS = read.csv("BOS.csv",sep = ",")
df_BDR = read.csv("BDR.csv",sep = ",")
df_PWM = read.csv("PWM.csv",sep = ",")


list_wea <- list(df_NYC,df_PHL,df_BOS,df_BDR,df_PWM)
list_reg <- list("NYC","PHL","BOS","BDR","PWM")
list_range <- c(1,2,3,4,5)

for (i in list_range) {
  list_wea[[i]] <- list_wea[[i]] %>% 
  dplyr::mutate(
    region = list_reg[[i]]
  )
}

  
#transfer date into date type  
df_weather <-list_wea %>% 
  dplyr::bind_rows(list_wea,id=NULL) %>% 
  dplyr::group_by(region)

df_weather$date = as.Date(df_weather$date)
df_weather

```


```{r weather}
#we need to analyze the temperature data for these 5 regions(New York,Pennsylvania,Massachusetts,Connecticut,Maine)

fig.title = "Northeast Temperature"

p <- df_weather %>%
  ggplot(aes(
    y = temp,
    x = date,
    col = region,
    alpha = 0.1,
    show.legend = FALSE
  )) +
  geom_point() +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  labs(
    title = "Northeast Region Temperature",
    caption = "Source: IEM",
    y = "Temperature (F)",
    x = ""
  )
ggplotly(p)
```

From the chart above, we found that these 5 regions have almost same temperature curve. However,except region New York City (NYC), much data between the range of (2016-2021) is missing. For convenience, New York City (NYC) data would be used to stand for the whole Northeast Region.
```{r}
#get continious future price for HO and CL
#we would like to trade for crack-spread

fig.title = "Correlations - GGally"
library(GGally)


HOdf %>%filter(Contracts== c('HO_01','HO_02','CL_01','CL_02')) %>% 
  tidyr::pivot_wider(names_from = Contracts, values_from = Price) %>%
  dplyr::select(-date) %>%
  na.omit() %>%
  GGally::ggpairs()
```

```{r}

HOdf %>% 
  dplyr::filter(Contracts == "HO_Crack_Spd")%>% 
  plotly::plot_ly(
    width = 700, height = 400,
    x = ~date,
    y = ~Price,
    name = ~Contracts
  ) %>% 
  plotly::add_lines() %>% 
  plotly::layout(
    title = "Crack Spread(HO22H - CL22H)", x = 0,
  xaxis = list(title = "Date"),
  yaxis = list(
    title = "$ per Barrel")
  )
```
```{r}
library(stats)
df_weather <- df_weather %>% filter(region == "NYC") %>% ungroup()



df_weather_ts <- dplyr::arrange(df_weather,date) %>% 
  dplyr::select(temp) %>% 
  stats::ts(start=c(2010,1),end = c(2021,1),frequency=12) #based on month 
df_weather_ts

df_weather_decomp <- df_weather_ts%>% 
  stats::decompose()

plot(df_weather_decomp)


weather_seasonal_adjusted <- df_weather_ts-df_weather_decomp$seasonal
plot(weather_seasonal_adjusted)

library(zoo)

#transfer the time series into df
df <- data.frame(date = yearmon(index(weather_seasonal_adjusted)), val = weather_seasonal_adjusted) 
df$date<- as.Date(df$date)

# df <- df %>% 
#   dplyr::mutate(
#     Electricity_Net_Generation = "ENG_Total"
#   )
colnames(df)[2] <- "temp"


df_weather_seasonal_adjusted <- df %>% 
  na.omit()

df_weather_seasonal_adjusted
```
```{r}
df_crack_spread <- filter(HOdf,Contracts == "HO_Crack_Spd")
df_crack_spread



df_crack_spread_ts <- dplyr::arrange(df_crack_spread,date) %>% 
  dplyr::select(Price) %>% 
  stats::ts(start=c(2010,1),end = c(2021,1),frequency=12) #based on month 
df_crack_spread_ts

df_crack_spread_decomp <- df_crack_spread_ts%>% 
  stats::decompose()

plot(df_crack_spread_decomp)

crack_spread_adjusted <- df_crack_spread_ts-df_crack_spread_decomp$seasonal
plot(crack_spread_adjusted)

library(zoo)

#transfer the time series into df
df <- data.frame(date = yearmon(index(crack_spread_adjusted)), val = crack_spread_adjusted) 
df$date<- as.Date(df$date)

# df <- df %>% 
#   dplyr::mutate(
#     Electricity_Net_Generation = "ENG_Total"
#   )
colnames(df)[2] <- "Price"


df_crack_spread_adjusted <- df %>% 
  na.omit()

df_crack_spread_adjusted
```

```{r}
#corr b/w crack_spread and temp
df_weather_seasonal_adjusted
df_crack_spread_adjusted

#merge the df

df_merge <- inner_join(df_crack_spread_adjusted,df_weather_seasonal_adjusted,copy = False)
df_merge
library(GGally)


df_merge %>%
  # filter (months.Date(date) == c("01"))%>% 
  dplyr::select(-date) %>%
  na.omit() %>%
  GGally::ggpairs()
```

# Result:
The result above indicate that the CORR is -0.244, negative correlative. The significance is 2 stars.
In other words, if the temperature goes up, the crack-spread may increase; if the the temperature goes down, the crack-spread may decrease.
The result is reasonable, since if the temperature decrease, it looks like the demand for HO would increase, which make the price of HO increase. Assumed the CL price does not change, the crack-spread would increase.


```{r}
df_ENG_Solar_ts <- dplyr::arrange(df_ENG_Solar,date) %>% 
  dplyr::select(absolute_change) %>% 
  stats::ts(start=c(2010,1), end= c(2020,4),frequency=12) #based on month 
# df_ENG_Solar_ts

df_ENG_Solar_decomp <- df_ENG_Solar_ts%>% 
  stats::decompose()

# plot(df_ENG_Solar_decomp)



ENG_Solar_seasonal <- df_ENG_Solar_decomp$seasonal
# plot(ENG_Solar_seasonal)

ENG_Solar_trend<-df_ENG_Solar_decomp$trend
plot(ENG_Solar_trend,ylim = c(0,1000/2))



df_ENG_Solar_ts <- dplyr::arrange(df_ENG_Solar,date) %>% 
  dplyr::select(value) %>% 
  stats::ts(start=c(2010,1), end= c(2020,4),frequency=12) #based on month 
# df_ENG_Solar_ts

df_ENG_Solar_decomp <- df_ENG_Solar_ts%>% 
  stats::decompose()

# plot(df_ENG_Solar_decomp)



ENG_Solar_seasonal <- df_ENG_Solar_decomp$seasonal
# plot(ENG_Solar_seasonal)

ENG_Solar_trend<-df_ENG_Solar_decomp$trend
plot(ENG_Solar_trend)
```

+ Clearly laid out components of SD balances.
+ State why they matter.
+ Provide both long term and short term views. Your trade horizon is weekly - can you identify clearly from the chart when a change occurs?
```{r}

```

### Market View

+ View based on SD indicators ensuring that your conclusions are clearly readable from your charts.
+ Build analytics that is relevant to your current view.
+ If you have explored more, put them in an appendix. 

## Desired Exposure

Translating your market view into strength of market call and allocate risk versus maximum limit

+ Evidence of converting market view into a strength of market call.
+ Strength of market call translates into allocating risk allocation vs your limits.

## Monetization Strategies

+ Evidence of exploring what we have covered in class.
+ How do you take those further with exploring various combinations along the grade, delivery location and delivery timing axis.
+ Diligence in being nimble in those in light of evolving market context.

## Risk Appetite

+ Allocate risk in the context of risk reward ensuring capital preservation.
+ Evidence of a basic framework that you utilize to make your decision. Best is if you can articulate it clearly and quantify it.

## Execution

+ What trades are you executing? 
+ Rationale stated clearly?
+ Entry/ Exit levels stated?
+ 

## Profit and Loss ("PL" Attribution

For each strategy:

+ Provide a grid of PL attribution by risk factors (flat price, time spread, crack,) 
+ Is it in line with your market call? Learnings...

## Lessons Learned

What have you learned from this project?

## Questions for Weekly Meeting with Prof

1. a...
2. b...






